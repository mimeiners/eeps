
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Sounderkennung mit Hilfe des Mojo V3 FPGA Boards und dem Sound &#8212; Electrical Engineering Projects with FPGA&#39;s</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link media="all" rel="stylesheet" type="text/css" href="https://dokie.li/media/css/dokieli.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="dokieli" src="https://dokie.li/scripts/dokieli.js"></script>
    <script kind="utterances">

    var commentsRunWhenDOMLoaded = cb => {
    if (document.readyState != 'loading') {
        cb()
    } else if (document.addEventListener) {
        document.addEventListener('DOMContentLoaded', cb)
    } else {
        document.attachEvent('onreadystatechange', function() {
        if (document.readyState == 'complete') cb()
        })
    }
}

var addUtterances = () => {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "https://utteranc.es/client.js";
    script.async = "async";

    script.setAttribute("repo", "mimeiners/fpga");
    script.setAttribute("issue-term", "pathname");
    script.setAttribute("theme", "github-light");
    script.setAttribute("label", "💬 comment");
    script.setAttribute("crossorigin", "anonymous");

    sections = document.querySelectorAll("div.section");
    if (sections !== null) {
        section = sections[sections.length-1];
        section.appendChild(script);
    }
}
commentsRunWhenDOMLoaded(addUtterances);
</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="https://mimeiners.github.io/eeps/lab/mojo.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="References" href="../class/02_lec.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/hsb-logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Electrical Engineering Projects with FPGA's</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../about/unsyllabus.html">
                    Unsyllabus
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lecture
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../class/01_lec.html">
   Introduction and Survey
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../class/02_lec.html">
   References
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Design Projects
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Sounderkennung mit Hilfe des Mojo V3 FPGA Boards und dem Sound
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/mimeiners/eeps"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/mimeiners/eeps/issues/new?title=Issue%20on%20page%20%2Flab/mojo.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/mimeiners/eeps/edit/master/lab/mojo.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/lab/mojo.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einleitung">
   Einleitung
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#der-mojo-baby">
   Der Mojo Baby
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#genutzte-toolchain">
   Genutzte Toolchain
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installation-des-ise-webpack">
     Installation des ISE WebPack
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installation-von-alchitry-labs">
     Installation von Alchitry Labs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#offnen-des-projektes">
     Öffnen des Projektes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aufbau-eines-projektes">
   Aufbau eines Projektes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sound-locator-projekt">
   Sound Locator Projekt
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probleme-mit-den-ip-cores-losen">
     Probleme mit den IP-cores lösen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funktionsprinzip-des-projektes">
   Funktionsprinzip des Projektes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#funktionstest">
     Funktionstest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fazit">
     Fazit
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Sounderkennung mit Hilfe des Mojo V3 FPGA Boards und dem Sound</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#einleitung">
   Einleitung
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#der-mojo-baby">
   Der Mojo Baby
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#genutzte-toolchain">
   Genutzte Toolchain
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installation-des-ise-webpack">
     Installation des ISE WebPack
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#installation-von-alchitry-labs">
     Installation von Alchitry Labs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#offnen-des-projektes">
     Öffnen des Projektes
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aufbau-eines-projektes">
   Aufbau eines Projektes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sound-locator-projekt">
   Sound Locator Projekt
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#probleme-mit-den-ip-cores-losen">
     Probleme mit den IP-cores lösen
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#funktionsprinzip-des-projektes">
   Funktionsprinzip des Projektes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#funktionstest">
     Funktionstest
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fazit">
     Fazit
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="sounderkennung-mit-hilfe-des-mojo-v3-fpga-boards-und-dem-sound">
<h1>Sounderkennung mit Hilfe des Mojo V3 FPGA Boards und dem Sound<a class="headerlink" href="#sounderkennung-mit-hilfe-des-mojo-v3-fpga-boards-und-dem-sound" title="Permalink to this headline">#</a></h1>
<section id="einleitung">
<h2>Einleitung<a class="headerlink" href="#einleitung" title="Permalink to this headline">#</a></h2>
<p>Diese Projektarbeit beschäftigt sich mit der Evaluation des <a class="reference external" href="https://alchitry.com/sound-locating-mojo">Sound Erkennungs</a>
Tutorials der Webiste <a class="reference external" href="https:///E//alchitry.com/">Alchitry</a>.</p>
<p>In diesem Tutorial nutzt Alchitry ihr eigens entwickeltes Mojo V3 Board (XILINX SPARTAN FPGA) und Soundshield mit sieben
Mikrofonen, um Audioquelle zu lokalisieren.</p>
<p>Das Mojo V3 Board ist ein Board, dass für das Erlernen der Erstellung von digitalen Schaltungen mit Hilfe von
Field-Programmable-Gate-Arrays (FPGA) genutzt werden kann. Wie man bereits am Namen erkennen kann, bietet ein FPGA die
Möglichkeit es jederzeit neu zu beschreiben (Field-Programmable). Dabei wird die Hardware mit Hilfe einer
Hardwarebeschreibungssprache (HDL) wie VHDL, Verilog oder wie im vorliegenden Projekt mit Lucid beschrieben.
Die Hardware nimmt entsprechend der Beschreibung exakt die Funktion an, die mit der Logik der Beschreibung intendiert
ist. Die Beschreibungssprache bewirkt, dass Logikgatter innerhalb des FPGA’s entsprechend der Funktion miteinander
verknüpft werden. So kann der Mojo V3 genutzt werden, um einen LED Ring anzusteuern und entsprechend die Richtung
anzuzeigen aus der ein Ton erkannt worden ist.</p>
<p>Im Folgenden wird die Hardware beschrieben und danach die Einrichtung der Toolchain Schritt für Schritt
erklärt. Außerdem wird der allgemeine Aufbau eines Hardware(FPGA)-Projektes erläutert; im Speziellen das Besipielprojekt
Sound Locator vom Mojo V3 Tutorial. In diesem Zusammenhang werden die so genannten IP-Cores erläutert, da Hardware und
Software erfahrungsgemäß selten so funkionieren wie es der Entwickler vorgesehen hat, wird außerdem auf Probleme
eingangen und wie diese behoben werden können. Hiernach wird eine Übersicht über den Signalfluss gegeben, ausgehend von
der Tonquelle, über die Aufnahme bis hin zur visuellen Darstellung. Für ein besseres Verständnis der Signalanalyse
und Signalwandlung, wird noch einmal auf die Darstellung von Signalen im Zeit- und Frequenzbereich
eingegangen. Außerdem wird der prinzipielle Aufbau der verwendeten Mikrofone beschrieben. Als letztes wird noch die
Puls-Dichte-Modulation (PDM) erklärt, bevor es im letzten Teil dieser Arbeit um den Funktionstest und ein Testen der
Grenzen der Sounderkennung geht.</p>
</section>
<section id="der-mojo-baby">
<h2><a class="reference external" href="https://www.adafruit.com/product/1553">Der Mojo</a> <a class="reference external" href="https://www.youtube.com/watch?v=c4ytuS8pVp4">Baby</a><a class="headerlink" href="#der-mojo-baby" title="Permalink to this headline">#</a></h2>
<figure class="align-default" id="fig-025">
<img alt="../_images/MojoBoard.png" src="../_images/MojoBoard.png" />
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Das Mojo Entwicklungsboard <span id="id1">[<a class="reference internal" href="#id45" title="Sparkfun. Mojo v3 fpga developement board. URL: https://www.sparkfun.com/products/retired/11953 (visited on 15.08.2022).">Sparkfun, n.d.</a>]</span></span><a class="headerlink" href="#fig-025" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Das Mojo V3 Board, zu erkennen in <a class="reference internal" href="#fig-025"><span class="std std-ref">Abbildung 1</span></a>, ist ein preiswertes (~70€, bei
<a class="reference external" href="https://de.aliexpress.com/item/32798926767.html?spm=a2g0o.ppclist.product.2.dc57fhXPfhXPEo&amp;pdp_npi=2%40dis%21EUR%21%E2%82%AC%2068%2C61%21%E2%82%AC%2068%2C61%21%21%21%21%21%40211b5a9616552327883654477e07b2%2164982667969%21btf&amp;_t=pvid%3Ab5fae29b-1699-49ff-9cdf-7850da36c207&amp;afTraceInfo=32798926767__pc__pcBridgePPC__xxxxxx__1655232788&amp;gatewayAdapt=glo2deu">AliExpress</a>
stand: Juni 2022) FPGA Entwicklungsboard auf dem ein Spartan 6 FPGA eingebaut ist, sowie ein ATmega32 Mikrocontroller, der
Arduino kompatibel ist. Dieser wird im Wesentlichen für die Programmierung des FPGA genutzt. Nach der Programmierung
wechselt der ATmega32 vom aktiven Modus in den slave Modus und das FPGA kann über den Mikrocontroller auf den seriellen
Port, analoge Eingänge und andere Funktionen des Mikrocontrollers zugreifen. Außerdem verfügt das Board über 84 digitale
I/O, die über die Steckleisten herausgeführt sind und 8 LEDs, die für allgemeine Programmierung genutzt werden können
<span id="id2">[<a class="reference internal" href="#id45" title="Sparkfun. Mojo v3 fpga developement board. URL: https://www.sparkfun.com/products/retired/11953 (visited on 15.08.2022).">Sparkfun, n.d.</a>]</span>.</p>
<figure class="align-default" id="fig-026">
<img alt="../_images/MicrophoneShield.png" src="../_images/MicrophoneShield.png" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Das Microphone Shield <span id="id3">[<a class="reference internal" href="#id37" title="aliexpress. Microphone shield for mojo v3. URL: https://de.aliexpress.com/item/33058437216.html (visited on 15.08.2022).">aliexpress, n.d.</a>]</span></span><a class="headerlink" href="#fig-026" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Auf dem Microphone Shield in <a class="reference internal" href="#fig-026"><span class="std std-ref">Abbildung 2</span></a> befinden sich sechs konzentrisch angeordnete Mikrofone, die um
ein siebtes Mikrofon in der Mitte herum auf dem Shield angebracht sind. Die Anschlüsse dieser Mikrofone sind über
Stiftleisten an der Unterseite des Boards herausgeführt und sind kompatibel zu den Steckleisten des Mojo Boards, wodurch
dieses auf das Mojo Board aufgesteckt werden kann.</p>
</section>
<section id="genutzte-toolchain">
<h2>Genutzte Toolchain<a class="headerlink" href="#genutzte-toolchain" title="Permalink to this headline">#</a></h2>
<p>Um eine Hardware beschreiben zu können bedarf es einer Toolchain, die es möglich macht Hardware zu
flashen. Die Toolchain für die Inbetriebnahme des Mojo V3 Boards besteht aus einem Projektierungstool <a class="reference external" href="https://alchitry.com/alchitry-labs">Alchitry
Labs</a> und einem Builder.</p>
<p>Für das Mojo V3 board bedarf es das
<a class="reference external" href="https://www.xilinx.com/products/design-tools/ise-design-suite/ise-webpack.html">ISE WebPack</a> von
<a class="reference external" href="https://www.xilinx.com/">Xilinx</a>.</p>
<p>Alchitry Labs wird hierbei genutzt, um das Projekt zu organisieren und die unterschiedlichen Teile des Projektes zu
erstellen. Der Builder ISE WebPack übersetzt letzten Endes die Beschreibung aus den unterschiedlichen Bestandteilen
des Projektierungstools in die eigentliche Logik innerhalb des FPGAs.</p>
<p>Das genutzte Betriebssystem in diesem Projekt ist Linux <a class="reference external" href="https://www.debian.org/News/2021/20210814">Debian 11</a>.
Im folgenden Abschnitt wird die Einrichtung der Toolchain ausführlich beschrieben.</p>
<section id="installation-des-ise-webpack">
<h3>Installation des ISE WebPack<a class="headerlink" href="#installation-des-ise-webpack" title="Permalink to this headline">#</a></h3>
<p>Vor der Installation von Alchitry Labs ist es ratsam, zunächst das ISE WebPack zu installieren. Auch eine Überprüfung der
Partitionierung des Rechners und des freien Festplattenspeicher ist ratsam, da das Archiv das aus dem Internet geladen
wird bereits 6,5 GB groß ist. Für die Installation benötigt das ISE WebPack weitere 18 GB Speicherplatz. Nachdem
sichergestellt wurde, dass ausreichend Speicherplatz für die Installation vorhanden ist kann das
Installationsverzeichnis von der <a class="reference external" href="https://www.xilinx.com/downloadNav/vivado-design-tools/archive-ise.html">Website</a>
heruntergeladen werden. Hier wird die die Version 14.7 ausgewählt. Unter diesem Punkt wird die ISE Design Suite - 14.7
Full Product ausgewählt und heruntergeladen. Es muss an dieser Stelle erwähnt werden, dass ein Nutzeraccount benötigt
wird, um diese Software herunter zu laden und zu installieren.</p>
<p>Nach dem Download geht es weiter zur eigentlichen Installation. Als erstes wird das Installationsverzeichnis
entpackt. Mit Hilfe des Terminals und des Befehls <strong>cd</strong> (change directory) wird in das Verzeichnis gewechselt in dem
das heruntergeladene Verzeichnis gespeichert ist.</p>
<p>(Hier: Downloads):</p>
<dl class="simple myst">
<dt>Terminalausgabe</dt><dd><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  mojo@fpga:~$ cd Downloads/
</pre></div>
</div>
</dd>
</dl>
<p>Im Verzeichnis wird das Archiv als nächstes entpackt.:</p>
<dl class="simple myst">
<dt>Terminalausgabe</dt><dd><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  mojo@fpga:/Downloads/$ tar -xvf Xilinx_ISE_DS_Lin_14.7_1015_1.tar
</pre></div>
</div>
</dd>
</dl>
<p>Die Optionen <strong>xvf</strong> beschreiben, dass das Archiv entpackt werden soll (x), dass die verarbeiteten Dateien ausführlich
aufeglistet werden (v) und dass das Archiv aus dem aktuellen Verzeichnis genommen werden soll (f) <span id="id4">[<a class="reference internal" href="#id35" title="Ulf Zibis. Tar. URL: https://wiki.ubuntuusers.de/tar/ (visited on 15.08.2022).">Zibis, n.d.</a>]</span>.
Nach diesen Vorarbeiten kann das Setup des Programmes gestartet werden.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Die Installation des ISE WebPacks sollte nach Möglichkeit mit Administrationsrechten ausgeführt werden. Das erleichtert
im weiteren Verlauf die Nutzung mit der weiteren Toolchain.</p>
</div>
<p>Die Installation kann mit dem folgenden Befehl gestartet werden:</p>
<dl class="simple myst">
<dt>Terminalausgabe</dt><dd><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  mojo@fpga:/Downloads/Xilinx_ISE_DS_Lin_14.7_1015_1$ sudo ./xsetup
</pre></div>
</div>
</dd>
</dl>
<p>In <a class="reference internal" href="#fig-01"><span class="std std-ref">Abbildung 3</span></a> sind die Geschäftsbedingungen aufgeführt, denen während der Installation zugestimmt werden müssen.</p>
<figure class="align-default" id="fig-01">
<img alt="../_images/Terms_and_conditions.png" src="../_images/Terms_and_conditions.png" />
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">Zustimmung zu den Terms and Conditions geben</span><a class="headerlink" href="#fig-01" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Nach der Zustimmung wird in <a class="reference internal" href="#fig-02"><span class="std std-ref">Abbildung 4</span></a> gezeigt, welches Produkt für die Installation ausgewählt werden
muss.</p>
<figure class="align-default" id="fig-02">
<img alt="../_images/AuswahlISE.png" src="../_images/AuswahlISE.png" />
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Auswahl des ISE WebPACKs für die Installation</span><a class="headerlink" href="#fig-02" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Im Folgefenster werden alle Haken gelassen wie der Installationswizard es vorschlägt. Eine Nutzung mehrer CPU-Kerne ist
sinnvoll, um die Installationszeit zu verringern.</p>
<p>Während der Installation kann die Zeit genutzt werden, um eine entsprechende Lizenz auf
<a class="reference external" href="https://www.xilinx.com/member/forms/license-form.html">Xlilinx</a> zu erstehen.
Nach Eingabe der persönlichen Daten wird die Lizenz für das ISE WebPack ausgewählt und die Lizenzdatei kann
heruntergeladen und dem Programm hinzugefügt werden.</p>
<p>Beim erstmaligen Start öffnet sich zunächst der Lizenzmanager, der noch einmal auf das Erlangen der Lizenz
hingeweist wie in <a class="reference internal" href="#fig-03"><span class="std std-ref">Abbildung 5</span></a> dargestellt.</p>
<figure class="align-default" id="fig-03">
<img alt="../_images/Licence_Manager_1.png" src="../_images/Licence_Manager_1.png" />
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">Möglichkeit zur Auswahl des Lizenztypes.</span><a class="headerlink" href="#fig-03" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Wurde die Lizenz heruntergeladen kann diese unter “Manage License” hinzugefügt werden. Innerhalb des Dialogfeldes
<a class="reference internal" href="#fig-04"><span class="std std-ref">Abbildung 6</span></a> kann zum Speicherort der Lizenzdatei navigiert werden.</p>
<figure class="align-default" id="fig-04">
<img alt="../_images/Licence_Manager_2.png" src="../_images/Licence_Manager_2.png" />
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">Unter Load Licence wird der Speicherort der Lizenzdatei ausgewählt.</span><a class="headerlink" href="#fig-04" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Nachdem das ISE WebPack</p>
<ol class="simple">
<li><p>heruntergeladen</p></li>
<li><p>installiert</p></li>
<li><p>gestartet und</p></li>
<li><p>lizensiert</p></li>
</ol>
<p>wurde, wird im nächsten Schritt die Programmierumgebung installiert.</p>
</section>
<section id="installation-von-alchitry-labs">
<h3>Installation von Alchitry Labs<a class="headerlink" href="#installation-von-alchitry-labs" title="Permalink to this headline">#</a></h3>
<p>Ein Großteil der Installation der Toolchain ist zu diesem Zeitpunkt bereits abgeschlossen. Das Einrichten von Alchitry
Labs stellt sich leichter dar, als es bei der Xilinx Software der Fall war.</p>
<p>Die Software ist auf der (Website)[<a class="reference external" href="https://alchitry.com/alchitry-labs">https://alchitry.com/alchitry-labs</a>] von Alchitry Labs unter dem Reiter Alchitry Labs
zu finden. Die Download Links sind unterhalb der Abbildung vom Programm zu finden. Für dieses Projekt wurde die
Linux-Version genutzt. Die Linux-Version bietet bei der Installation deutliche Vorteile in der Einrichtung im Vergleich
zur Windows-Version, da diese für Windows 10 und 11 nicht mehr optimiert ist. Nach dem Download von knapp 18 MB muss das
geladene Archiv ausgepackt werden. Hierfür kann der gleiche Befehl mit geändertem Dateinamen genutzt werden.</p>
<dl class="simple myst">
<dt>Terminalausgabe</dt><dd><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  mojo@fpga:/Downloads/$ tar -xvf alchitry-labs-1.2.7-linux.tar
</pre></div>
</div>
</dd>
</dl>
<p>Nach der Installation wird in den Unterordner “alchitry-labs-1.2.7” navigiert und das Programm mit folgendem Befehlt gestartet:</p>
<dl class="simple myst">
<dt>Terminalausgabe</dt><dd><div class="highlight-none notranslate"><div class="highlight"><pre><span></span>  bash alchitry-labs
</pre></div>
</div>
</dd>
</dl>
<p>Ist die Installation bisher erfolgreich und korrekt öffnet sich nun die Programmierumgebung. Die Software erfragt beim
ersten Starten den Installationsort des Builders ISE WebPack. Im Programmfenster kann über “Settings” und “ISE Location”
über ein Dialogfeld der Installationsort des ISE WEbPack ausgewählt werden.( siehe: <a class="reference internal" href="#fig-05"><span class="std std-ref">Abbildung 7</span></a>). Hierbei
ist  darauf zu achten, dass der Ordner mit der entsprechenden Versionsnummer ausgewählt wird (hier: 14.7). Die Software
Alchitry Labs gibt entsprechende Hinweise innerhalb des Dialoges.</p>
<figure class="align-default" id="fig-05">
<img alt="../_images/Alchitry_Licence.png" src="../_images/Alchitry_Licence.png" />
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">Auswahl des ISE WebPack Installationsortes</span><a class="headerlink" href="#fig-05" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Ab diesem Zeitpunkt ist es möglich Projekte zu öffnen und zu erstellen.</p>
</section>
<section id="offnen-des-projektes">
<h3>Öffnen des Projektes<a class="headerlink" href="#offnen-des-projektes" title="Permalink to this headline">#</a></h3>
<p>Beim ersten Starten von Alchitry Labs startet automatisch ein Dialog, in dem erfragt wird, ob bereits ein Projekt
vorhanden ist. Siehe: <a class="reference internal" href="#fig-06"><span class="std std-ref">Abbildung 8</span></a></p>
<figure class="align-default" id="fig-06">
<img alt="../_images/First_Start.png" src="../_images/First_Start.png" />
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">Erste Projektauswahl</span><a class="headerlink" href="#fig-06" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Durch die Auswahl “No” wird der User in ein weiteres Dialogfenster geführt, indem dieser ein Projekt erstellen kann.</p>
<p>Dieses Dialogfenster ist in <a class="reference internal" href="#fig-07"><span class="std std-ref">Abbildung 9</span></a> zu sehen. Im Feld “Project Name:” wird der Wunschname des neuen
Projektes eingegeben. Im folgenden Reiter “Workspace” steht die Arbeitsumgebung. Hier werden Projekte abgespeichert
und Projektumgebungen (Arbeitsverzeichnisse) erstellt, die notwendige Dateien für den “Build-Prozess” bereitstellen. Im
dritten Reiter wird das entsprechende Board ausgewählt. Für dieses Projekt ist das das Mojo Board. Das Programm erstellt
hier für automatisch die Bezüge zu Hardware, damit das Projekt funktionsfähig gebaut werden kann. Die Sprache
(“Language”) die ausgewählt werden muss um ein funktionierendes Beispielprojekt laden zu können ist hier das
programmeigene Lucid. Es ist ebenfalls möglich innerhalb der Umgebung in Verilog zu coden, allerdings gibt es für
Verilog keine Beispielprojekte. Die Beispielprojekte sind auschließlich in Lucid geschrieben. Über ein Dropdown Menü ist
es nun möglich, das Sound Locator Projekt auszuwählen und zu laden.</p>
<figure class="align-default" id="fig-07">
<img alt="../_images/New_Project.png" src="../_images/New_Project.png" />
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text">Einstellungen zum Öffnen des Sound Locator Beispiels</span><a class="headerlink" href="#fig-07" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Durch einen letzten Mausklick auf den Button “Create” wird das Beispielprojekt erstellt. Im nächsten Abschnitt wird
beschrieben, welche Arten von Files man innerhalb des Projektes finden kann und was diese tun. Die Inbetriebnahme des
Projektes wird im darauffolgenden Abschnitt beschrieben.</p>
</section>
</section>
<section id="aufbau-eines-projektes">
<h2>Aufbau eines Projektes<a class="headerlink" href="#aufbau-eines-projektes" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><u><strong>Source</strong></u></p></li>
</ul>
<p>Der erste Teil innerhalb dieses Projektes sind die Source-Dateien auch Module genannt. Diese beschreiben alle Ein- und
Ausgänge der unterschiedlichen Hardware. Die im Projekt genutzten Source-Dateien sind in <a class="reference internal" href="#fig-08"><span class="std std-ref">Abbildung 10</span></a>
dargestellt. Für das Sound Locator Projekt sind das die Hann-Funktion, der LED-Ring, das mojo-top modul,
welches das Mojo Board beschreibt, die pdm-mics zur Definition der Mikrophone und das sound_locator Modul in dem das
Delay zur Sound Erkennung ermittelt wird.</p>
<figure class="align-default" id="fig-08">
<img alt="../_images/Source.png" src="../_images/Source.png" />
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Die Source-Dateien sind als erstes im Projekt zu finden</span><a class="headerlink" href="#fig-08" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><u><strong>Components</strong></u></p></li>
</ul>
<p>Components sind teils vorinstallierte, teils selbst geschriebene Bausteine, die für spezielle Funktionen verwendet werden
können. Im vorliegenden Projekt finden sich vielfach Lucid-Files, mit der Dateiendung <strong>.luc</strong>. Diese wurden vom
Entwickler erstellt, können sich aber auch in der XILINX-Umgebung befinden. Die in diesem Projekt genutzten sind in
<a class="reference internal" href="#fig-09"><span class="std std-ref">Abbildung 11</span></a> dargestellt.</p>
<figure class="align-default" id="fig-09">
<img alt="../_images/Components.png" src="../_images/Components.png" />
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Als zweites sind die Components im Projekt aufgeführt.</span><a class="headerlink" href="#fig-09" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><u><strong>Cores</strong></u></p></li>
</ul>
<p>Die Cores oder auch IP-Cores sind vorgefertigte weitestgehend von XILINX geteste Bausteine, die spezielle Aufgaben
erledigen können und werden von XILINX mitgeliefert. IP steht für Intellectual Property, also geistiges Eigentum. Diese
Bausteine sind weitestgehend spezifiziert und bieten somit den Vorteil, dass diese in einem Design mehrfach
wiederverwendet werden können. Fertige IP-Cores gibt es von Buskommunikation über digitale Signalverarbeitung wie FFT
bis hin zu Multimedia wie Ethernet oder Bluetooth. In diesem Projekt gibt es drei IP cores. Zum einen den
Dezimationsfilter, welcher die einkommende PDM Signale dezimiert, um die Informationen mit verringerter Samplefrequenz
zu extrahieren. Als zweites gibt es den mag_phase_calculator der aus den einkommenden Signalen die Amplitude und die
Phase errechnet und als letztes den xfft_v8_0-core der die FFT auf die einkommenden Signale anwendet.</p>
<figure class="align-default" id="fig-010">
<img alt="../_images/Cores.png" src="../_images/Cores.png" />
<figcaption>
<p><span class="caption-number">Fig. 12 </span><span class="caption-text">Der dritte Reiter beinhaltet die IP-Cores</span><a class="headerlink" href="#fig-010" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><u><strong>Constraints</strong></u></p></li>
</ul>
<p>Dargestellt in <a class="reference internal" href="#fig-011"><span class="std std-ref">Abbildung 13</span></a> sind die drei User-constraints-files von debugger, microphone shield und vom
Mojo Board. In diesen Dateien werden die Timing-Eigenschaften, sowie die Pin-Eigenschaften, physikalischen Eigenschaften
und Grenzen beschrieben. Diese Dateien werden benötigt, um dem Syntheseschritt (ISE WebPack) die letzten
Informationen zu geben, wie das Projekt erstellt werden soll.</p>
<figure class="align-default" id="fig-011">
<img alt="../_images/Constraints.png" src="../_images/Constraints.png" />
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Als letztes gibt es die Constraints im Projekt</span><a class="headerlink" href="#fig-011" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="sound-locator-projekt">
<h2>Sound Locator Projekt<a class="headerlink" href="#sound-locator-projekt" title="Permalink to this headline">#</a></h2>
<p>Im Vorfeld wurden bereits die Hardware, sowie die unterschiedlichen Funktionsblöcke, die das Sound Locator Projekt
besitzt beschrieben. Die Dokumentation des Projektes von O’Reilly verspricht ein Plug’n’Play mit der Hardware. Die
Untersuchungen innerhalb dieses Projekts haben jedoch gezeigt, dass noch weitere Probleme gelöst werden müssen, bevor
das Projekt auf den FPGA geflasht werden kann. In diesem Abschnitt werden diese Probleme genauer beleuchtet, wie diese
zu lösen sind und im Anschluss wird die Funktion der Sound-Erkennung getestet.</p>
<section id="probleme-mit-den-ip-cores-losen">
<h3>Probleme mit den IP-cores lösen<a class="headerlink" href="#probleme-mit-den-ip-cores-losen" title="Permalink to this headline">#</a></h3>
<p>Erinnern wir uns an die IP-Cores, die im letzten Abschnitt beschrieben wurden. Diese stellen eine fertige
Funktionseinheit, wie zum Beispiel den Dezimationsfilter, dar. Ausgerechnet diese IP-Cores machen beim ersten
Flash-Versuch Probleme und es kommt folgende Meldung die in <a class="reference internal" href="#fig-012"><span class="std std-ref">Abbildung 14</span></a> dargestellt ist.</p>
<figure class="align-default" id="fig-012">
<img alt="../_images/Fehlermeldung_Cores.png" src="../_images/Fehlermeldung_Cores.png" />
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">Angezeigte Fehlermeldung beim ersten Flashversuch</span><a class="headerlink" href="#fig-012" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Alchitry Labs zeigt an, dass es die Dateien für die IP-Cores nicht lesen kann. Schaut man in die Ordnerstruktur und
vergleicht diese mit dem agezeigten Pfad, so scheint sich hier ein Fehler bei der Programmierung der Software
eingeschlichen zu haben, der es zunächst unmöglich macht, das Projekt zu bauen.</p>
<blockquote>
<div><p><span style="color:green"><strong>erik&#64;erik:</strong></span><span style="color:blue"><strong>~/alchitry/SoundLocator</strong></span>$ ls</p>
<p><span style="color:blue"><strong>constraint</strong></span>  <span style="color:blue"><strong>coreGen</strong></span> SoundLocator.alp
<span> style=”color:blue”&gt;<strong>source</strong></span>  <span style="color:blue"><strong>work</strong></span></p>
</div></blockquote>
<p>Es sind in dieser Ansicht vier Ordner zu sehen. Vergeicht man diese vier Ordner mit dem geforderten Pfad von Alchitry
Labs aus <a class="reference internal" href="#fig-012"><span class="std std-ref">Abbildung 12</span></a> ist zu erkennen, dass der Ordner <strong>cores</strong> vergeblich in diesem Verzeichnis zu
suchen ist. Dieses Vezeichnis wurde automatisch vom Programm erstellt, was die Vermutung nahelegt, dass der Aufbau des
Verzeichnises “hard coded” ist. Nach einiger Suche innerhalb des Programmverzeichnises konnte die Codezeile, die dafür
verantwortich ist, nicht gefunden werden. Statdessen wurde für die Inbetriebnahme der Hardware ein Workaround
gefunden. Die nötigen Dateien befinden sich alle im <strong>coreGen</strong> Ordner.</p>
<p>Das händische korrigieren des Pfades in drei Schritten:</p>
<ol class="simple">
<li><p>Umbenennen des  <strong>coreGen</strong> zu <strong>cores</strong>.</p></li>
<li><p>Innerhalb dieses Ordners, erstellen der jeweiligen Ordner für <strong>Decimation Filter</strong>, <strong>xfft_v8.0</strong> und
<strong>mag_phase_calculator</strong>.</p></li>
<li><p>Verschieben der Dateien für den jeweiligen core in den entsprechend erstellten Ordner.</p></li>
</ol>
<p>Nachdem diese Schritte durchgeführt wurden, kann das Projekt gebaut werden und ermöglicht es uns, das Mojo Board zu
flashen und die Funktion des Programmes zu testen.</p>
</section>
</section>
<section id="funktionsprinzip-des-projektes">
<h2>Funktionsprinzip des Projektes<a class="headerlink" href="#funktionsprinzip-des-projektes" title="Permalink to this headline">#</a></h2>
<p>In diesem Abschnitt wird die Funktion des gesamten Aufbaus bestehend aus Mojo mit aufgestecktem Microphone Shield
evaluiert. Zunächst wird das Funktionsprinzip des Projektes erläutert. In <a class="reference internal" href="#fig-013"><span class="std std-ref">Abbildung 15</span></a> ist der
Signalfluss der Sounderkennung dargestellt. Am Anfang steht ein Ton in Form einer sinusförmigen Schallwelle an. Diese
besteht nicht aus nur einer Frequenz wie in <a class="reference internal" href="#fig-013"><span class="std std-ref">Abbildung 15</span></a> dargestellt, sondern setzt sich aus
verschiedenen Frequenzen zusammen. Dieses Frequenzspektrum wird ebenfalls dargestellt und diskutiert. Die analoge
Sinuswelle wird durch ein Wandlungssystem in die digitale Domäne übertragen. Auf dem Microphone Shield sind für diese
Wandlung sogenannte digitale MEMS PDM Mikrofone, die diese Wandlung vornehmen. Die Mikrofone geben eine
Puls-Dichte-Modulation (PDM) aus, welche direkt auf das FPGA gegeben wird. Dieses Signal wir dann vom FPGA weiter
verarbeitet und anschließend wird das Ergebnis der Richtungserkennung auf dem LED-Ring für den Anwender sichtbar
gemacht.</p>
<figure class="align-default" id="fig-013">
<img alt="../_images/SignalFlow.png" src="../_images/SignalFlow.png" />
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">Übersicht Signalfluss</span><a class="headerlink" href="#fig-013" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Der erste Block des Signalflusses enthält die akustische Welle. Die akustische Welle ist nichts anderes als eine
Schallwelle, welche durch das komprimieren und dekomprimieren der Luft entsteht. Für die theoretisch ideale Betrachtung
wird in der Physik eine ideale winzige Punktschallquelle angenommen von der aus kugelförmig, also dreidimensional, die
Schallwellen in alle Richtungen abgestrahlt werden. Diese Punktquelle und die Ausbreitung der Schallwellen von dort aus
sind in <a class="reference internal" href="#fig-014"><span class="std std-ref">Abbildung 16</span></a> dargestellt. Diese Wellenfronten in Verbindung mit den dargestellten Strahlen
kennzeichnen die Richtung der Schallwellen. Wellenfronten sind hierbei Flächen, bei der die Luftteilchen wertgleiche
Auslenkungen, also gleiche Amplituden, aufgrund der erzeugten Schwingung besitzen <span id="id5">[<a class="reference internal" href="#id20" title="David Halliday and Robert Resnick und Jearl Walter. Physik für natur- und ingenieurswissenschaftliche Studiengänge. Wiley-VCH Verlag GmbH &amp; Co. KGaA, 3rd edition, 2020. URL: https://ebookcentral.proquest.com/lib/bremende/detail.action?docID=5940459.">Halliday and und Jearl Walter, 2020</a>]</span>.</p>
<figure class="align-default" id="fig-014">
<img alt="../_images/Schallwellen.png" src="../_images/Schallwellen.png" />
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Zweidimensionale Darstellung zur Ausbreitung einer Schallwelle <span id="id6">[<a class="reference internal" href="#id20" title="David Halliday and Robert Resnick und Jearl Walter. Physik für natur- und ingenieurswissenschaftliche Studiengänge. Wiley-VCH Verlag GmbH &amp; Co. KGaA, 3rd edition, 2020. URL: https://ebookcentral.proquest.com/lib/bremende/detail.action?docID=5940459.">Halliday and und Jearl Walter, 2020</a>]</span></span><a class="headerlink" href="#fig-014" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Wie bereits erwähnt breiten sich diese Schallwellen kugelförmig im Raum aus und werden deshalb auch
sphärische Wellen genannt. Diese sphärischen Wellen sind wie in <a class="reference internal" href="#fig-014"><span class="std std-ref">Abbildung 16</span></a> gekrümmt.
Je weiter man sich von der Punktquelle entfernt, umso geringer wird diese Krümmung und die Schallwelle kann als Ebene
verstanden werden. Diese Wellen werden dann ebene oder planare Wellen genannt <span id="id7">[<a class="reference internal" href="#id20" title="David Halliday and Robert Resnick und Jearl Walter. Physik für natur- und ingenieurswissenschaftliche Studiengänge. Wiley-VCH Verlag GmbH &amp; Co. KGaA, 3rd edition, 2020. URL: https://ebookcentral.proquest.com/lib/bremende/detail.action?docID=5940459.">Halliday and und Jearl Walter, 2020</a>]</span>.</p>
<p>Die Intensität der Schallwelle ist abhängig von der Amplitude der Schallwelle. Die Intensität verringert sich
quadratisch in Abängigkeit zum Abstand zur Tonquelle:</p>
<div class="math notranslate nohighlight">
\[
I = \frac{P_{s}}{4 \, \pi \, r^{2}}
\]</div>
<p>Wobei <span class="math notranslate nohighlight">\(I\)</span> die Intensität der Schallwelle ist <span class="math notranslate nohighlight">\(P\)</span> die Leistung durch die Schallwelle und <span class="math notranslate nohighlight">\(r\)</span> der Abstand zur
Schallquelle <span id="id8">[<a class="reference internal" href="#id20" title="David Halliday and Robert Resnick und Jearl Walter. Physik für natur- und ingenieurswissenschaftliche Studiengänge. Wiley-VCH Verlag GmbH &amp; Co. KGaA, 3rd edition, 2020. URL: https://ebookcentral.proquest.com/lib/bremende/detail.action?docID=5940459.">Halliday and und Jearl Walter, 2020</a>]</span>.</p>
<p>Da das menschliche Ohr einen großen Bereich an Intensitäten wahrnehmen kann, wird für die Bewertung von Schallintensitäten
die Dezibelskala verwendet. Angaben in der Dezibelskala sind immer Vergleiche (Relationen), bei dem der gemessene Wert
mit einem Standardwert verglichen wird. In diesem Fall wird diese als Schallpegel oder Schalldruckpegel bezeichnet und
folgendermaßen berechnet:</p>
<div class="math notranslate nohighlight">
\[
\beta = 10 dB \cdot \frac{I}{I_{0}}
\]</div>
<p>Wobei <span class="math notranslate nohighlight">\(\beta\)</span> der resultierende Schalldruckpegel ist. <span class="math notranslate nohighlight">\(I\)</span> beschreibt die Intensität der gemessenen Schallwelle und <span class="math notranslate nohighlight">\(I_{0}\)</span>
beschreibt einen standardisierten Referenzwert für die Intensität (<span class="math notranslate nohighlight">\(I_0 = 10^{-12} \frac{W}{m^{2}}\)</span>). <span id="id9">[<a class="reference internal" href="#id20" title="David Halliday and Robert Resnick und Jearl Walter. Physik für natur- und ingenieurswissenschaftliche Studiengänge. Wiley-VCH Verlag GmbH &amp; Co. KGaA, 3rd edition, 2020. URL: https://ebookcentral.proquest.com/lib/bremende/detail.action?docID=5940459.">Halliday and und Jearl Walter, 2020</a>]</span></p>
<p>Um einen Ton zu erzeugen muss diese (De-)Komprimierung der Luft mit einer definierten Frequenz erzeugt werden. Um
beispielsweise den Kammerton C zu erzeugen, muss eine Schallwelle mit einer Frequenz von <span class="math notranslate nohighlight">\(f\)</span>=440 Hz erzeugt
werden. Idealisiert sieht diese Schallwelle aus wie in <a class="reference internal" href="#fig-015"><span class="std std-ref">Abbildung 17</span></a> dargestellt.</p>
<figure class="align-default" id="fig-015">
<img alt="../_images/Sine_Only.png" src="../_images/Sine_Only.png" />
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Sinuswelle mit <span class="math notranslate nohighlight">\(f\)</span>=440 Hz</span><a class="headerlink" href="#fig-015" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Aus dieser Darstellung ist es ein Einfaches, die Frequenz des Signals abzulesen und damit das Signal zu
rekonstruieren. In der realen Welt ist die Wahrheit nicht so eindeutig und das eintreffende Signal auf das
Mikrofon ist mit Rauschen überlagert wie in <a class="reference internal" href="#fig-016"><span class="std std-ref">Abbildung 18</span></a> dargestellt.</p>
<figure class="align-default" id="fig-016">
<img alt="../_images/Noisy_Source_Signal.png" src="../_images/Noisy_Source_Signal.png" />
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Sinuswelle mit <span class="math notranslate nohighlight">\(f\)</span>=440 Hz überlagert mit Rauschen</span><a class="headerlink" href="#fig-016" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Im dargestellten Zeitbereich ist es nicht einzuschätzen, welches Signal der Grundton ist und welche Frequenz er hat.
Um die Reaktion der Hardware auf die eintreffenden Töne besser einschätzen oder erklären zu können, ist es deshalb
nötig, das Signal nicht im Zeitbereich zu betrachten, sondern mit Hilfe einer FFT (Fast-Fourier-Transformation) im
Frequenzbereich (Spektralanalyse). Das Frequenzspektrum des Signals aus <a class="reference internal" href="#fig-016"><span class="std std-ref">Abbildung 18</span></a> ist in <a class="reference internal" href="#fig-017"><span class="std std-ref">Abbildung
19</span></a> zu finden.</p>
<figure class="align-default" id="fig-017">
<img alt="../_images/FFT_Source.png" src="../_images/FFT_Source.png" />
<figcaption>
<p><span class="caption-number">Fig. 19 </span><span class="caption-text">Frequenzspektrum des verrauschten Signals.</span><a class="headerlink" href="#fig-017" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>An der Y-Achse ist die Amplitude der Frequenzanteile aufgetragen und auf der X-Achse sind die unterschiedlichen
Frequenzen dargestellt. Sie zeigt uns aus welchen Frequenzanteilen das Ausgangssignal zusammengesetzt ist. Das Rauschen
mit seinen vielen Frequenzen, die gleichermaßen im Signal enthalten sind, verschwinden mit Hinblick auf die Amplitude
förmlich im Gegensatz zum eigentlichen Signal. Mit Hilfe dieser Methode ist es möglich auch aus im Zeitbereich
verrauschten oder uneindeutigen Signalen das gesuchte Signal herauszufinden bzw zu erfahren, welche Frequenzen im
untersuchten Signal enthalten sind.</p>
<p>Nachdem geklärt wurde, welche Eingangssignale zu erwarten sind, kann der Fokus auf die akustische Aufnahme gerichtet
werden. Auf dem Microphone Shield sind sieben Mikrofone mit der Bezeichnung SPK0415HM4H zu finden. Diese Mikrophone sind
digitale Mikro-Elektro-Mechanische Systeme (MEMS). Das bedeutet, dass durch Herstellungsmethoden der Halbleiterindustrie
ein Bauteil erzeugt wurde, dass sowohl elektronische als auch mechanische Eigenschaften vereint. Wie in <a class="reference internal" href="#fig-018"><span class="std std-ref">Abbildung
20</span></a> zu erkennen ist, besitzt ein solches Mikrofon einen Sound Port, dies ist eine Öffnung im Gehäuse (Can)
des Bauteils. Hier kann der Ton auf die eigentliche Struktur des Mikrofons auftreffen. Die Öffnung ist hier oben auf dem
Gehäuse, kann bei anderen Mikrofonen aber auch am Boden des Gehäuses sein. Darunter befindet sich eine Membran (Glob Top
Molding) über einer Halbleiterträgerstruktur. Die Membran und die Trägerstruktur sind zwei gerade, gegenüberliegende
Flächen zwischen denen ein Material zu finden ist, das als Dielektrikum verstanden werden kann. Dieser Aufbau verhält
sich wie ein Kondensator mit einer bekannten Kapazität. Beim Auftreffen von Schall gerät die Membran in Bewegung, was
zur Folge hat, dass sich die Kapazität des Kondensators, durch die Verringerung des Abstandes zwischen den zwei Flächen,
ändert. Diese Änderung wird von der Anwender Spezifischen Schaltung (ASIC) erkannt und entsprechend verarbeitet. Ob ein
analoges oder digitales Signal ausgegeben wird, entscheidet sich hier. Entweder das analoge Signal wird vom ASIC
bereitgestellt oder ein weiterer Wandler (ADC) befindet sich innerhalb des Systems, welcher das analoge Signal in ein
digitales Signal umsetzt. Bei den digitalen Signalen kann es sich um Pulse-Code-Modulierte (PCM) oder um
Puls-Dichte-Modulierte (PDM) Signale handeln. Puls-Code-Modulierte Signale werden hier nicht weiter behandelt, sollen
aber der Vollständigkeit wegen Erwähnung finden <span id="id10">[<a class="reference internal" href="#id19" title="MEMS oder ECM: Mikrofontechnologien im Vergleich. 21.02.2019. URL: https://www.digikey.de/de/articles/mems-vs-ecm-comparing-microphone-technologies (visited on 15.08.2022).">Bruce Rose, 21.02.2019</a>]</span>.</p>
<figure class="align-default" id="fig-018">
<img alt="../_images/MEMS.png" src="../_images/MEMS.png" />
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text">Aufbau eines MEMS Mikrofons <span id="id11">[<a class="reference internal" href="#id19" title="MEMS oder ECM: Mikrofontechnologien im Vergleich. 21.02.2019. URL: https://www.digikey.de/de/articles/mems-vs-ecm-comparing-microphone-technologies (visited on 15.08.2022).">Bruce Rose, 21.02.2019</a>]</span></span><a class="headerlink" href="#fig-018" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>In diesem Projekt werden Mikrofone verwendet, die Puls-Dichte-Modulierte (PDM) Signale verwenden. Bei der
Puls-Dichte-Modulation wird die Information der Amplitude des Signals über die Puls-Dichte dargestellt. Das heißt, dass
eine Häufung von logischen High (1) Pegeln eine hohe Amplitude und eine Häufung von logischen Low (0) Pegeln eine
niedrige Amplitude bedeutet. Bei der Wandlung durch ein MEMS Mikrophon kann das PDM-Signal eines Sinustons
folgendermaßen aussehen.</p>
<figure class="align-default" id="fig-019">
<img alt="../_images/Pulse_Density.png" src="../_images/Pulse_Density.png" />
<figcaption>
<p><span class="caption-number">Fig. 21 </span><span class="caption-text">Übersicht zwischen analogem Signal und Puls-Dichte-moduliertem Signal <span id="id12">[<a class="reference internal" href="#id18" title="Jimmy Wang. Pdm example on the nrf52832. URL: https://devzone.nordicsemi.com/nordic/nordic-blog/b/blog/posts/pdm-example-on-the-nrf52832 (visited on 15.08.2022).">Wang, n.d.</a>]</span></span><a class="headerlink" href="#fig-019" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>In <a class="reference internal" href="#fig-019"><span class="std std-ref">Abbildung 21</span></a> ist wie beschrieben zu erkennen, dass mit höheren Amplituden vermehrt ein High Pegel zu
finden ist. Durch diese periodische Häufung von hohen und niedrigen Amplituden ist nicht nur die Amplitude sondern
ebenfalls die Frequenz im PDM-Signal kodiert. Das PDM-Signal ist der letzte Punkt, bevor die Verarbeitung des FPGAs
beginnt. Als nächstes kann die Funktion des Projektes betrachtet werden.</p>
<p>Für die Funktion des Projektes werden zunächst Annahmen vom Autor getroffen. Die wichtigste Annahme ist, dass die
Richtung des Tons nur in einem zweidimensionalen Raster horizontal zum Mojo Board auf das FPGA auftreffen darf. Das ist
dem physikalischen Aufbau des Microphone Shields geschuldet, da alle Mikrofone auf einer Ebene verbaut sind. Außerdem
wird angenommen, dass es sich bei den auftreffenden Schallwellen um eine eine gerade Wellenfront, also um eine planare
Welle handelt. Die letzte Annahme ist, dass jede Frequenz eines Soundsamples aus einer einzigen Richtung kommt
<span id="id13">[<a class="reference internal" href="#id26" title="Justin Rajewski. Learning FPGAs Digital Design for Beginners with Mojo and Lucid HDL. O'Reilley Media, 2017.">Rajewski, 2017</a>]</span>.</p>
<p>Die Sounderkennung mit dem Mojo errechnet die Richtung des auftreffenden Sounds aus der Phasenverschiebung
zwischen den äußeren und dem zentralen Mikrophon. Der auf die Mikrofone treffende Ton wird in ein PDM-Signal
umgewandelt und dieses PDM-Signal wird simultan vom FPGA abgetastet. Auf diese Samples wird eine FFT angewandt,
wodurch das PDM-Signal von der Zeit- in die Frequenzdomäne überführt wird. Als Ausgabe aus der FFT erhält man
nun für jedes Sample eine komplexe Zahl. Bestehend aus dem Realteil, der die Amplitude des eingehenden Signals darstellt
und dem Imaginärteil, der die Phase des eingehenden Signals darstellt. Diese können in einem Koordinatensystem
aufgetragen werden. In <a class="reference internal" href="#fig-020"><span class="std std-ref">Abbildung 22</span></a> ist beispielfhaft für drei Mikrofone das Prinzip dargestellt. Die
schwarzen Kreise stellen die Position von drei Mikrofonen auf dem Microphone Shield dar mit ihren in Klammern
dargestellten Koordinaten. Der Mittelpunkt des Koordinatensystems ist ebenfalls als Koordinate des zentralen Mikrofons
zu verstehen. In Blau in der oberen linken Ecke ist die Richtung dargestellt, aus der ein Ton auf die Mikrofone
trifft. Das Auftreffen bewirkt eine Verzögerung (Delay) der jeweiligen äußeren Mikrofone im Vergleich zum mittleren
Mikrofon. Mithilfe dieses Delays bzw. mit der Phasenverschiebung zueinander (die Verzögerung ist lediglich der Quotient
aus Phasenverschiebung und Frequenz, wodurch diese beiden Werte proportinal zueinander sind) und der Positionsvektoren
der unterschiedlichen Mikrofone kann nun die Richtung des Tons bestimmt werden. Hierzu werden die Ortsvektoren mit dem
errechneten Delay skaliert, wodurch die violett skalierten Vektoren entstehen. Durch Vektoraddition kann ein
Summenvektor erstellt werden, der in die Richtung der Tonquelle zeigt (gelb)<span id="id14">[<a class="reference internal" href="#id26" title="Justin Rajewski. Learning FPGAs Digital Design for Beginners with Mojo and Lucid HDL. O'Reilley Media, 2017.">Rajewski, 2017</a>]</span>. Rajewski hat dies
Richtungen in 16 verschiedene Bins eingeteilt, wodurch die Einteilung auf die LEDs erfolgt.</p>
<figure class="align-default" id="fig-020">
<img alt="../_images/SoundirectionPrinciple.png" src="../_images/SoundirectionPrinciple.png" />
<figcaption>
<p><span class="caption-number">Fig. 22 </span><span class="caption-text">Vektorielle Darstellung des Erkennungsprinzips <span id="id15">[<a class="reference internal" href="#id26" title="Justin Rajewski. Learning FPGAs Digital Design for Beginners with Mojo and Lucid HDL. O'Reilley Media, 2017.">Rajewski, 2017</a>]</span></span><a class="headerlink" href="#fig-020" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="funktionstest">
<h3>Funktionstest<a class="headerlink" href="#funktionstest" title="Permalink to this headline">#</a></h3>
<p>Die beschriebene Funktion soll mit den nächsten Tests überprüft werden. Die grundsätzlichen Funktionstest beinhalten
einen Sprachtest und einen Test bei dem mit einer Gitarre ein Lied angespielt wird. Für den ersten Test wird der Mojo
auf einem Holztisch platziert und es wird das Alphabet durchgesprochen. Die Tonquelle ist in diesem Video von Links und die
Quelle ist horizontal verschoben zum Mojo, um die Annahmen des Erfinders zu berücksichtigen, dass die Tonquelle auf der
selben Ebene sein muss wie die Mikrofone. Es ist zu erkennen, dass bei S-Lauten (die Buchstaben C, S, X, Z) mehr als nur
eine LED leuchtet. Alle anderen Buchstaben haben insgesamt eine eindeutige Antwort des Mojos verursacht. Eine eindeutige
Antwort heißt, dass die LED geleuchtet hat, aus der der Ton auf den Mojo getroffen ist.</p>
<div class="video_container">
	<video width="320" height="240" controls="true" allowfullscreen="true" title="Testtitel">
		<source src="../mov/Alphabet.mp4" label="Alphabet"/>
	</video>
    <div class="overlay"> <p>Alphabet Test</p> </form>  </div>
</div>
<p>Betrachtet man zu den Beobachtungen nun das Frequenzsspektrum zu den ersten sieben Buchstaben des Alphabets, ist zu
erkennen, dass der größete Schallpegel bei Frequenzen zwischen <span class="math notranslate nohighlight">\(f\)</span>=60 Hz und <span class="math notranslate nohighlight">\(f\)</span>=400 Hz zu finden ist. Der Buchstabe “C”
ist in dieser <a class="reference internal" href="#fig-021"><span class="std std-ref">Abbildung 23</span></a> der dritte Balken von Links. Das Diagramm ist ein
Frequenz-Zeit-Diagramm. Hierbei sind auf der Y-Achse die unterschiedlichen Frequenzanteile aufgeführt. Auf der X-Achse
findet sich der Zeitpunkt in der Audiospur. Die Codierung des Schallwellenpegels ist in der Helligkeit der Balken zu
erkennen. Diese Darstellung war die Beste für diese Anwendung, da durch die Art des Versuchs verschiedene Töne zu
unterschiedlichen Zeiten auftreffen. Dieses Diagramm bietet eine übersichtliche Darstellung für diese Zwecke. Für den
Buchstaben “C” ist zu erkennen, dass zu Beginn des Buchstabens ein höherer Schalldruckpegel zu erkennen ist. Dieser reicht
von einer Frequenz von <span class="math notranslate nohighlight">\(f\)</span>=4 kHz bis zu mehr als <span class="math notranslate nohighlight">\(f\)</span>=16 kHz. Interessanterweise ist eine konträre Beobachtung beim
Buchstaben “F” zu erkennen. Der zweite Balken von Rechts hat zu Beginn des Buchstabens ein ähnliches Frequenzmuster wie
die anderen. Nach einer kurzen Zeit verteilt sich der Schalldruckpegel gleichmäßig auf eine größere Bandbreite an
Frequenzen. Hier konnte jedoch eine gute Funktion des Mojo beobachtet werden. Der Schalldruckpegel bei diesem Versuch
konnte etwa zwischen <span class="math notranslate nohighlight">\(\beta\)</span>=60 dB und <span class="math notranslate nohighlight">\(\beta\)</span>=70 dB mit dem Schalldruckpegelmesser gemessen werden.</p>
<figure class="align-default" id="fig-021">
<img alt="../_images/AlphaG.png" src="../_images/AlphaG.png" />
<figcaption>
<p><span class="caption-number">Fig. 23 </span><span class="caption-text">Frequenzspektrum für die Buchstaben A bis G</span><a class="headerlink" href="#fig-021" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Nach dieser Beobachtung ist ein weiterer grundsätzlicher Funktionstest mit einer anderen Tonquelle durchgeführt
worden. In diesem Funktionstest wurde der Song “Come as you are” von Nirvana angespielt, um die Reaktion vom Mojo zu
testen. Die Quelle des Geräusches ist in diesem Video unterhalb des Mojo’s. Es ist zu erkennen, dass die unterste
LED am hellsten leuchtet und die Richtung damit erkannt wird. Allerdings ist ebenfalls zu sehen, dass auch LEDs auf der
anderen Seite des Kreises aufleuchten.</p>
<div class="video_container">
	<video width="320" height="240" controls="true" allowfullscreen="true" title="Testtitel">
		<source src="../mov/Come_as_you_are.mp4" label="Gitarren Spiel"/>
    </video>
    <div class="overlay">
        <p>Test mit Gitarrenspiel</p>
        </form>
    </div>
</div>
<p>Das Frequenzspektrum ist in der nachfolgenden <a class="reference internal" href="#fig-022"><span class="std std-ref">Abbildung 24</span></a> zu erkennen. Der Schalldruckpegel der Frequenzen
scheint hier weniger breit gefächert zu sein als bei dem vorangegangenen Funktionstest. Die Funktion konnte auch hierbei
im Wesentlichen nachgewiesen werden, auch wenn es bei diesem Test zum leuchten der gegenüberliegenden LED gekommen
ist. Das mehrere LEDs leuchten könnte an der Art der Tonquelle liegen. Wie bei der Sprache ist es bei einem
Saiteninstrument wie bei einer Gitarre so, dass die Schwingung nicht sauber eine Frequnez besitzt. Eine Annahme des
Projektes war, dass eine Frequenz lediglich aus einer Richtung kommt. Die Durchführung des Projektes in einem üblichen
Raum kann allerdings dazu führen, dass Reflexionen an den Wänden des Raumes entstehen und somit eine Frequenz
ggf. scheinbar aus zwei oder mehreren Richtung kommen kann. Der Schalldruckpegel der während des Versuchs gemsesen wurde
lag bei rund <span class="math notranslate nohighlight">\(\beta\)</span>=70 dB.</p>
<figure class="align-default" id="fig-022">
<img alt="../_images/comeasyouare.png" src="../_images/comeasyouare.png" />
<figcaption>
<p><span class="caption-number">Fig. 24 </span><span class="caption-text">Frequenzspektrum des Intros von “Come as you are” von Nirvana.</span><a class="headerlink" href="#fig-022" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Die Funktionstests konnten die prinzipielle Funktion nachweisen. Aus den Beobachtungen der ersten beiden Funktionstests
kann gefolgert werden, dass die Erkennung eines Tones frequenzabhängig ist, da beim Alphabettest die Buchstaben
nicht eindeutig erkannt wurden, bei denen höhere Frequenzanteile (<span class="math notranslate nohighlight">\(f &gt; 10 \, kHz\)</span> “C” und “F”) enthalten sind.
Damit stellt sich die Fragen, welche Grenzen der Erkennung bei der Frequenz zu finden sind. Eine weitere Frage die sich
beim Konzipieren des Experimentes gestellt hat ist, ob ebenfalls die Lautstärke eines Tones eine Rolle spielt. Um die
Grenzen der Sounderkennung zu ermitteln wurde sich in diesem Experiment dazu entschieden, dieses weiter im privaten
Wohnzimmer durchzuführen und nicht in einem speziell eingerichtetem schallarmen Raum, da die Sounderkennung dazu dienen
soll, Geräuschquellen zu unterscheiden und die Richtung des gesuchten Tons zu ermitteln. Der Aufbau für dieses
Experiment ist in den vorangegangenen Videos schon erkennbar, ist der Übersicht wegen nochmal schematisch in <a class="reference internal" href="#fig-023"><span class="std std-ref">Abbildung
25</span></a> dargestellt. Das Mojo Board mitsamt des Microphone Shield ist im Zentrum des Aufbaus platziert. Die
Soundquelle ist eine Bluetoothbox der Firma Bose und wurde 10 cm oberhalb des Mojo’s aufgestellt. Hier wird ein
Sinussignal einer definierten Frequenz und Lautstärke ausgegeben. Um die Lautsärke in Decibel (dB) prüfen zu können,
wird ein Schalldruckpegel Messgerät auf der gleichen Höhe wie das zentrale Mikrofon auf dem Microphone Shield platziert,
um möglichst exakt die Lautstärke einstellen bzw. prüfen zu können. Bei dem Experiment wirde Gehörschutz getragen, da
Schalldruckpegel von bis zu <span class="math notranslate nohighlight">\(\beta\)</span>=111 dB getestet werden.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Bei einem solchen Versuch muss immer ein Gehörschutz getragen werden! Diese Lautstärken können das Hörvermögen
verringern und sind gesundheitsschädlich!</p>
</div>
<figure class="align-default" id="fig-023">
<img alt="../_images/Setup_experiment.png" src="../_images/Setup_experiment.png" />
<figcaption>
<p><span class="caption-number">Fig. 25 </span><span class="caption-text">Versuchsaufbau für den Funktionstest</span><a class="headerlink" href="#fig-023" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Zunächst wird die Grenze der Lautstärke getestet. Hierfür wird die Lautsärke einen Sinustones mit einer Frequenz von
<span class="math notranslate nohighlight">\(f\)</span>=1 kHz langsam von <span class="math notranslate nohighlight">\(\beta\)</span>= 40 dB Schalldruckpegel bis <span class="math notranslate nohighlight">\(\beta\)</span>=111 dB Schaldruckpegel erhöht und die Funktion wird
beobachtet. Jede Lautstärke wird für eine Zeit <span class="math notranslate nohighlight">\(t\)</span>=3 s gehalten. Die Funktion gilt als sicher vorhanden, solange
ausschließlich die LED leuchtet, die in die Richtung der Tonquelle ausgerichtet ist. Die gewählte Frequenz wurde anhand
des Datenblattes der Mikrofone gewählt. Die Testbedigungen für die Mikrofone sind im Datenblatt mit einer Frequenz von
<span class="math notranslate nohighlight">\(f\)</span>=1 kHz und einem Schalldruckpegel <span class="math notranslate nohighlight">\(\beta\)</span>=91 dB angegeben.</p>
<p>Für die Soundausgabe wurde folgendes Pythonskript mit dem Paket PyAudio genutzt.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Created on Fri Jul 15 14:11:25 2022</span>

<span class="sd">@author: Erik Müller</span>

<span class="sd">from: https://stackoverflow.com/questions/8299303/generating-sine-wave-sound-in-python </span>
<span class="sd">      https://www.codegrepper.com/code-examples/python/python+generate+sine+wave+pyaudio</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">pyaudio</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">pyaudio</span><span class="o">.</span><span class="n">PyAudio</span><span class="p">()</span>

<span class="n">volume</span> <span class="o">=</span> <span class="mf">1.0</span>  <span class="c1"># range [0.0, 1.0]</span>
<span class="n">fs</span> <span class="o">=</span> <span class="mi">44100</span>  <span class="c1"># sampling rate, Hz, must be integer</span>
<span class="n">duration</span> <span class="o">=</span> <span class="mf">3.0</span>  <span class="c1"># in seconds, may be float</span>
<span class="n">f</span> <span class="o">=</span> <span class="mf">2000.0</span>  <span class="c1"># sine frequency, Hz, may be float</span>


<span class="c1"># generate samples, note conversion to float32 array</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">fs</span><span class="o">*</span><span class="n">duration</span><span class="p">)</span><span class="o">*</span><span class="n">f</span><span class="o">/</span><span class="n">fs</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>


<span class="c1"># for paFloat32 sample values must be in range [-1.0, 1.0]</span>
<span class="n">stream</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="n">pyaudio</span><span class="o">.</span><span class="n">paFloat32</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="n">fs</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="c1"># Play. May repeat with different volume values (if done interactively)</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">volume</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span> 
    <span class="n">stream</span><span class="o">.</span><span class="n">write</span><span class="p">((</span><span class="n">volume</span><span class="o">*</span><span class="n">samples</span><span class="p">)</span><span class="o">.</span><span class="n">tobytes</span><span class="p">())</span>
    <span class="n">volume</span> <span class="o">=</span> <span class="n">volume</span> <span class="o">+</span> <span class="mf">0.1</span>

<span class="n">stream</span><span class="o">.</span><span class="n">stop_stream</span><span class="p">()</span>

<span class="n">stream</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">p</span><span class="o">.</span><span class="n">terminate</span><span class="p">()</span>

<span class="c1"># First Volume Percentage: 13% up to 61 dB</span>
<span class="c1"># Second up to 41% to 80dB</span>
<span class="c1"># third up to 70% up to 100 dB</span>
<span class="c1"># fourth up to 100% and 111 dB</span>
</pre></div>
</div>
<p>Aus dem Code ist zu erkennen, dass mit jedem Schleifendurchlauf die Lautsärke um 0.1, also 10% erhöht wird. Der Versuch
musste allerdings in vier Durchläufen durchgeführt werden wobei das Skript in jedem der Durchläufe einmal ausgeführt
wurde. Bei jedem Durlauf wurde die Systemlautstärke des genutzten Laptops erhöht, da es nicht möglich war inerhalb einer statischen
Systemeinstellung den gesamten Lautstärkebereich von <span class="math notranslate nohighlight">\(\beta\)</span>=40 dB bis <span class="math notranslate nohighlight">\(\beta\)</span>=111 dB zu durchlaufen. Die genutzten
Systemlautstärken in Prozent sind am Ende des Pythonskriptes im Kommentar zu erkennen.</p>
<div class="video_container">
    <video width="320" height="240" controls="true" allowfullscreen="true" title="Testtitel">
      <source src="../mov/Projekt_dB_Test-1.mp4" label="dB-Sweep"/>
    </video>
    <div class="overlay"> <p>dB-Sweep von 40 dB bis 111 dB Schallpegel</p> </form> </div>
</div>
<p>In dem Video ist zu sehen, dass die Funktion sicher ab einem Schalldruckpegel von <span class="math notranslate nohighlight">\(\beta\)</span>=47 dB gegeben ist. Mit
steigender Lautstärke ist die Funktion immer deutlicher, bis zu einem Schalldruckpegel von <span class="math notranslate nohighlight">\(\beta\)</span>=99,9 dB laut
Anzeige des Schalldruckpegelmessers. Oberhalb dieses Pegels beginnen alle LEDs auf dem Microphone Shield zu leuchten,
wodurch keine eindeutige Erkennung der Tonrichtung mehr möglich ist.</p>
<p>Aus diesem Grund wurde ein weiteres Experiment durchgeführt. Der Aufbau bleibt wie dargestellt in
<a class="reference internal" href="#fig-020"><span class="std std-ref">Abbildung 22</span></a>. In diesem Experiment wird die Lautstärke konstant gehalten bei 91 dB und die Frequenz wird
angepasst. Der Grund für die 91 dB Schalldruckpegel lassen sich wie erwähnt im Datenblatt der Mikrofone finden. Hierfür
wird das Pythonskript insofern abgeändert, als dass lediglich eine Frequenz einmalig ausgegeben wird. Die for-Schleife
wird für diesen Versuch ausgeblendet. Bei jeder Frequenz wurde die Lautstärke jedes mal auf 91 dB Schalldruckpegel
eingestellt, bevor das Video aufgenommen wurde.</p>
<div class="video_container">
    <video width="320" height="240" controls="true" allowfullscreen="true" title="Testtitel">
      <source src="../mov/Projekt_Frequenz_test.mp4" label="Frequenz Test"/>
    </video>
    <div class="overlay"> <p>Test Frequenzmessung</p> </form> </div>
</div>
<p>Es ist zu beobachten, dass die Funktion im unteren Frequenzbereich (<span class="math notranslate nohighlight">\(f\)</span>=440 Hz bis <span class="math notranslate nohighlight">\(f\)</span>=700 Hz) zwar zu erkennen
ist, allerdings leuchten die Richtungs-LEDs nur schwach. Ein eindeutiges Erkennen der LEDs ist ab einer Frequenz von
<span class="math notranslate nohighlight">\(f\)</span>=710 Hz gegeben. Die höchste Frequenz bei der eine eindeutige Funktion beobachtet werden konnte war <span class="math notranslate nohighlight">\(f\)</span>=4937 Hz. Bei
höheren Frequenzen konnte beobachtet werden, dass entweder die oberste LED nicht mehr leuchtet oder das meherere LEDs
gleichzeitig leuchten, wodurch eine eindeutige Erkennung der Richtung nicht mehr gegeben ist.</p>
<p>Das Frequenzspektrum der Audiospur des Videos ist in <a class="reference internal" href="#fig-024"><span class="std std-ref">Abbildung 26</span></a> zu sehen. Es ist zu erkennen, dass die
Energiedichte bei den unteren Frequenzen höher ist, als bei den oberen Freqeunzen. Interessanterweise sind bei den
unteren Frequenzen außerdem Oberwellen/Harmonische erkennbar.</p>
<figure class="align-default" id="fig-024">
<img alt="../_images/Spec_project.png" src="../_images/Spec_project.png" />
<figcaption>
<p><span class="caption-number">Fig. 26 </span><span class="caption-text">Spectrumsverlauf des Frequenztests</span><a class="headerlink" href="#fig-024" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Bis hierher konnte die grundsätzliche Funktion und ihre Grenzen getestet werden. Einen Beweis ist diese Arbeit jedoch
noch schuldig geblieben. In der theoretischen Erläuterung des Signalflusses wurde erwähnt, dass das PDM-Signal die
Informationen über den eingehenden Ton beinhaltet. Hierfür wurde der Datenausgang eines Mikrofons mit einem Logic Analyzer
verbunden, um das ausgehende Signal aufzunehmen. Der Aufbau ist in <a class="reference internal" href="#fig-027"><span class="std std-ref">Abbildung 27</span></a> zu erkennen.</p>
<figure class="align-default" id="fig-027">
<img alt="../_images/Setup_spectrum.png" src="../_images/Setup_spectrum.png" />
<figcaption>
<p><span class="caption-number">Fig. 27 </span><span class="caption-text">Frequenzspektrum des PDM Signals</span><a class="headerlink" href="#fig-027" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Es wurde ein Ton mit einer Frequenz von <span class="math notranslate nohighlight">\(f\)</span>=1 kHz von der Bose Box abgespielt. Innerhalb dieses Zeitraums wurde
das ausgehende Signal vom Mikrofon und vom Datenlogger aufgenommen. Die erzeugten Daten wurden mit folgendem
Pythonskript ausgewertet:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Created on Fri Sep 23 08:46:42 2022</span>

<span class="sd">@author: erik.mueller</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.fft</span> <span class="kn">import</span> <span class="n">fft</span><span class="p">,</span> <span class="n">fftfreq</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s1">&#39;../../data/1khznew1.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">skip_header</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">skip_footer</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># extracting all time values</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">:]</span>  <span class="c1"># all amplitude value</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>  <span class="c1"># getting length of y vector</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># %%</span>
<span class="c1"># sample spacing</span>
<span class="n">T</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">((</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>  <span class="c1"># defining Period length</span>
<span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="mf">1e6</span>
<span class="c1"># yf = fft(y) # fft only from y signal </span>

<span class="n">w</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">windows</span><span class="o">.</span><span class="n">hann</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>  <span class="c1"># hanning window with N samples</span>
<span class="n">ywf</span> <span class="o">=</span> <span class="n">fft</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">w</span><span class="p">)</span>                    <span class="c1"># fft of signal multiplied with hanning window</span>
<span class="n">xf</span> <span class="o">=</span> <span class="n">fftfreq</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">T</span><span class="p">)[:</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span>         <span class="c1"># getting x-values for fft plot</span>

<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">xf</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">],</span> <span class="mf">2.0</span><span class="o">/</span><span class="n">N</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">ywf</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">N</span><span class="o">//</span><span class="mi">2</span><span class="p">]),</span> <span class="s1">&#39;-b&#39;</span><span class="p">)</span>

<span class="c1"># plotting FFT signal</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="mi">988</span><span class="p">,</span> <span class="mf">0.0089</span><span class="p">,</span> <span class="s1">&#39;xr&#39;</span><span class="p">)</span>   <span class="c1"># plotting mark at maximum</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;FFT&#39;</span><span class="p">,</span> <span class="s1">&#39;1kHz Peak&#39;</span><span class="p">])</span>  <span class="c1"># legend</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>                        <span class="c1"># grid</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20000</span><span class="p">)</span>                <span class="c1"># limiting window</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Frequency in Hz&quot;</span><span class="p">)</span>     <span class="c1"># labeling x axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Amplitude in dB&quot;</span><span class="p">)</span>     <span class="c1"># labeling y axis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>                        <span class="c1"># show plot</span>
</pre></div>
</div>
<p>Mit Hilfe dieses Skriptes wurde dann das Spektrum erzeugt, welches in <a class="reference internal" href="#fig-028"><span class="std std-ref">Abbildung 28</span></a> dargestellt
ist. Im Spektrum ist zu erkennen, dass die höchste Amplitude des Frequenzspektrums bei <span class="math notranslate nohighlight">\(f \approx\)</span> 1 kHz zu
finden ist. Demnach trägt das PDM-Signal die Information über die Frequenz des eingespielten akustischen Signals.</p>
<figure class="align-default" id="fig-028">
<img alt="../_images/PDM_Spectrum.png" src="../_images/PDM_Spectrum.png" />
<figcaption>
<p><span class="caption-number">Fig. 28 </span><span class="caption-text">Aufbau zur Untersuchung des PDM Ausgangssignals.</span><a class="headerlink" href="#fig-028" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Was hier ebenfalls sichtbar wird ist, dass die Betragsdifferenz nicht eindeutig wirkt. Das zeugt von einem
schlechten Signal-zu-Rausch-Verhältnis (SNR). Ein Grund für das schlechte SNR kann am Aufbau des Versuchs liegen. Die
Ausgangsfrequenz des PDM-Signals betrug messtechnisch <span class="math notranslate nohighlight">\(f_{Out}\)</span>=5.8 MHz und für die Verbindung von Logic Analyzer
und Microphone Shield wurden Jumper-Wire verwendet. Das kann dazu geführt haben, dass andere Signale auf die Leitung
eingekoppelt haben und somit störende Frequenzanteile mitgemessen wurden.</p>
</section>
<section id="fazit">
<h3>Fazit<a class="headerlink" href="#fazit" title="Permalink to this headline">#</a></h3>
<p>Das Mojo V3 Board bietet mit dem Microphone Shield eine gute Möglichkeit einen Einblick in komplexes FPGA Design zu
wagen. Neben diesem sehr interessanten Projekt für fortgeschrittenes FPGA Design finden sich auf Alchitry Labs weitere
Projekte für jeden Schwierigkeitsgrad. Mit Lucid bieten Sie ebenfalls einen niederschwelligen Einstieg für alle, die
Microkontroller Programmierung gewöhnt sind, da Lucid die Hürde kleiner machen soll als den Sprung von z.B. C zu
VHDL. Sollte jemand größeres Interesse daran finden, FPGA Design weiter zu vertiefen und eigene Projekte zu entwickeln,
würde ich nach diesen Erfahrungen und Beobachtungen empfehlen den Fokus auf VHDL oder Verilog als Beschreibungsspraache
zu legen und nicht zu lange den Umweg über Lucid zu nehmen.</p>
<p>Das FPGA was auf dem Mojo V3 Board verbaut ist wird nicht mehr von XILINX unterstützt und auch Alchitry Labs hat weitere
Boards entwickelt, welche von Ihnen Emfohlen werden und die sicherlich einen Blick wert sind. Die Untersuchungen von
Alchitry labs und von diesem Projekt sind mit dieser Arbeit noch nicht abgeschlossen. Folgende Aufgaben könnten für
zukünfitge Projekte interessant sein:</p>
<ol class="simple">
<li><p>Übertragen der Projektdateien von Lucid in VHDL oder Verilog. Lucid ist eine von Alchitry Labs entwickelte
Beschreibungssprache, die es Programmierern von Mikrocontrollern leichter machen soll von der
Mikrocontroller-Programmierung auf FPGA-Programmierung umzusteigen bzw. dieses überhaupt zu probieren.</p></li>
<li><p>Ein weiterer Versuch könnte sein zu testen, ob andere Frequenzgrenzen erreicht werden können, wenn andere
Lautstärkepegel genutzt werden können.</p></li>
<li><p>Das Gleiche gilt umgekehrt bei der Frage, ob andere Lautstärkepegel erreicht werden können, wenn eine andere Frequenz
für den Versuch genutzt wird.</p></li>
</ol>
<div class="docutils container" id="id16">
<dl class="citation">
<dt class="label" id="id45"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>)</span></dt>
<dd><p>Sparkfun. Mojo v3 fpga developement board. URL: <a class="reference external" href="https://www.sparkfun.com/products/retired/11953">https://www.sparkfun.com/products/retired/11953</a> (visited on 15.08.2022).</p>
</dd>
<dt class="label" id="id37"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>aliexpress. Microphone shield for mojo v3. URL: <a class="reference external" href="https://de.aliexpress.com/item/33058437216.html">https://de.aliexpress.com/item/33058437216.html</a> (visited on 15.08.2022).</p>
</dd>
<dt class="label" id="id35"><span class="brackets"><a class="fn-backref" href="#id4">3</a></span></dt>
<dd><p>Ulf Zibis. Tar. URL: <a class="reference external" href="https://wiki.ubuntuusers.de/tar/">https://wiki.ubuntuusers.de/tar/</a> (visited on 15.08.2022).</p>
</dd>
<dt class="label" id="id20"><span class="brackets">4</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id6">2</a>,<a href="#id7">3</a>,<a href="#id8">4</a>,<a href="#id9">5</a>)</span></dt>
<dd><p>David Halliday and Robert Resnick und Jearl Walter. <em>Physik für natur- und ingenieurswissenschaftliche Studiengänge</em>. Wiley-VCH Verlag GmbH &amp; Co. KGaA, 3rd edition, 2020. URL: <a class="reference external" href="https://ebookcentral.proquest.com/lib/bremende/detail.action?docID=5940459">https://ebookcentral.proquest.com/lib/bremende/detail.action?docID=5940459</a>.</p>
</dd>
<dt class="label" id="id19"><span class="brackets">5</span><span class="fn-backref">(<a href="#id10">1</a>,<a href="#id11">2</a>)</span></dt>
<dd><p>MEMS oder ECM: Mikrofontechnologien im Vergleich. 21.02.2019. URL: <a class="reference external" href="https://www.digikey.de/de/articles/mems-vs-ecm-comparing-microphone-technologies">https://www.digikey.de/de/articles/mems-vs-ecm-comparing-microphone-technologies</a> (visited on 15.08.2022).</p>
</dd>
<dt class="label" id="id18"><span class="brackets"><a class="fn-backref" href="#id12">6</a></span></dt>
<dd><p>Jimmy Wang. Pdm example on the nrf52832. URL: <a class="reference external" href="https://devzone.nordicsemi.com/nordic/nordic-blog/b/blog/posts/pdm-example-on-the-nrf52832">https://devzone.nordicsemi.com/nordic/nordic-blog/b/blog/posts/pdm-example-on-the-nrf52832</a> (visited on 15.08.2022).</p>
</dd>
<dt class="label" id="id26"><span class="brackets">7</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id14">2</a>,<a href="#id15">3</a>)</span></dt>
<dd><p>Justin Rajewski. <em>Learning FPGAs Digital Design for Beginners with Mojo and Lucid HDL</em>. O'Reilley Media, 2017.</p>
</dd>
</dl>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "mimeiners/eeps",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./lab"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../class/02_lec.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">References</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By E. Müller and M. Meiners(HSB)<br/>
  
    <div class="extra_footer">
      <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>